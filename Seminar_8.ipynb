{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы построения оптического потока по последовательности изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original was taken from [here](https://habr.com/ru/post/201406/)\n",
    "\n",
    "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
    "\n",
    "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
    "\n",
    "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/Publications/2011/Bro11a/tennis.png)\n",
    "\n",
    "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-03-30 03:49:16--  https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\n",
      "Resolving www.bogotobogo.com (www.bogotobogo.com)... 173.254.30.214\n",
      "Connecting to www.bogotobogo.com (www.bogotobogo.com)|173.254.30.214|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2018126 (1,9M) [video/mp4]\n",
      "Saving to: ‘slow_traffic_small.mp4’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  2%  138K 14s\n",
      "    50K .......... .......... .......... .......... ..........  5%  281K 10s\n",
      "   100K .......... .......... .......... .......... ..........  7% 5,60M 7s\n",
      "   150K .......... .......... .......... .......... .......... 10%  297K 6s\n",
      "   200K .......... .......... .......... .......... .......... 12% 3,68M 5s\n",
      "   250K .......... .......... .......... .......... .......... 15% 19,3M 4s\n",
      "   300K .......... .......... .......... .......... .......... 17%  301K 4s\n",
      "   350K .......... .......... .......... .......... .......... 20% 9,37M 4s\n",
      "   400K .......... .......... .......... .......... .......... 22%  262K 4s\n",
      "   450K .......... .......... .......... .......... .......... 25% 36,6M 3s\n",
      "   500K .......... .......... .......... .......... .......... 27% 46,9M 3s\n",
      "   550K .......... .......... .......... .......... .......... 30% 50,7M 3s\n",
      "   600K .......... .......... .......... .......... .......... 32% 55,8M 2s\n",
      "   650K .......... .......... .......... .......... .......... 35%  304K 2s\n",
      "   700K .......... .......... .......... .......... .......... 38% 4,55M 2s\n",
      "   750K .......... .......... .......... .......... .......... 40% 24,5M 2s\n",
      "   800K .......... .......... .......... .......... .......... 43%  148K 2s\n",
      "   850K .......... .......... .......... .......... .......... 45% 37,4M 2s\n",
      "   900K .......... .......... .......... .......... .......... 48% 52,1M 2s\n",
      "   950K .......... .......... .......... .......... .......... 50% 47,6M 2s\n",
      "  1000K .......... .......... .......... .......... .......... 53% 77,3M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 55% 82,3M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 58% 65,3M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 60%  113M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 63% 10,9M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 65% 3,03M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 68% 5,31M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 71% 12,4M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 73%  350K 1s\n",
      "  1450K .......... .......... .......... .......... .......... 76% 2,18M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 78% 10,4M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 81% 4,25M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 83%  351K 0s\n",
      "  1650K .......... .......... .......... .......... .......... 86% 3,19M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 88% 4,04M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 91% 4,25M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 93%  354K 0s\n",
      "  1850K .......... .......... .......... .......... .......... 96% 3,15M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 98% 3,98M 0s\n",
      "  1950K .......... ..........                                 100% 24,9M=2,2s\n",
      "\n",
      "2022-03-30 03:49:20 (902 KB/s) - ‘slow_traffic_small.mp4’ saved [2018126/2018126]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O slow_traffic_small.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lucas-Kanade (sparse)\n",
    "\n",
    "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
    "\n",
    "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
    "\n",
    "Вопрос 0. Получите математически выражение в матричном виде для подсчета $dx, dy$ в случае алгоритма Лукаса-Канаде.\n",
    "\n",
    "Вопрос 1. Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`.\n",
    "\n",
    "Вопрос 2. В `cv2.calcOpticalFlowPyrLK` есть параметр, отвечающий за ImagePiramid. Зачем нужна пирамида изображений в случае вычисления оптического потока?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivative_x(\n",
    "    prevImg,\n",
    "    keypoint,\n",
    "    winSize,\n",
    ") -> np.array:\n",
    "    \n",
    "    for i in range(winSize):\n",
    "        for j in range(winSize):\n",
    "            pass\n",
    "\n",
    "# arguments like in cv2 lib\n",
    "def mycalcOpticalFlowPyrLK(\n",
    "    prevImg,\n",
    "    nextImg,\n",
    "    prevPts,\n",
    "    nextPts, #None is our case\n",
    "    winSize,\n",
    "    #maxLevel, if you want to be an expert in CV,\n",
    "    #uncomment it and apply in LK method :)\n",
    ") -> np.array:\n",
    "    \n",
    "    '''\n",
    "    You should return output vector of 2D points\n",
    "    (with single-precision floating-point coordinates)\n",
    "    containing the calculated new positions of input features in the second image\n",
    "    '''\n",
    "    nextPts = []\n",
    "    \n",
    "    for keypoint in prevPts:\n",
    "        \n",
    "        derivative_x = get_derivative_x(prevImg, keypoint, winSize)\n",
    "        derivative_y = get_derivative_y(prevImg, keypoint, winSize)\n",
    "        derivative_t = get_derivative_t(prevImg, keypoint, winSize)\n",
    "        \n",
    "        # find a matrix and solve linear equation system\n",
    "        pass\n",
    "        \n",
    "        # find result coordinates\n",
    "        nextPts.append()\n",
    "        \n",
    "    return np.expand_dims(np.stack(nextPts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 913/914 [00:02<00:00, 374.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_path = 'slow_traffic_small.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners = 100,\n",
    "    qualityLevel = 0.3,\n",
    "    minDistance = 7,\n",
    "    blockSize = 7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    #window size\n",
    "    winSize  = (15, 15),\n",
    "    #image piramid\n",
    "    maxLevel = 2,\n",
    "    #after the specified maximum number of iterations criteria.maxCount\n",
    "    #or when the search window moves by less than criteria.epsilon.\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    ")\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "for i in tqdm(range(length)):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "        \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calculate optical flow\n",
    "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        prevImg=old_gray,\n",
    "        nextImg=frame_gray,\n",
    "        prevPts=p0,\n",
    "        nextPts=None,\n",
    "        **lk_params,\n",
    "    )\n",
    "    \n",
    "    # Select good points where status is equal 1\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "        \n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "        \n",
    "    img = cv2.add(frame, mask)\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    out.write(img)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось\n",
    "\n",
    "Вопрос 3. Какие проблемы в текущей реализации вы увидели при просмотре результирующего видео? Как их можно устранить? Напишите код, устраняющий одну из проблем, покажите результат до/после."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video('output.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Farneback (dense)\n",
    "\n",
    "Метод Horn–Schunck носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 913/914 [00:50<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "for i in tqdm(range(length)):\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "        \n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    prvs = next\n",
    "    \n",
    "    out.write(bgr)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video('output.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
